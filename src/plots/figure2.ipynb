{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f911c77c",
   "metadata": {},
   "source": [
    "# figure 2 code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ec44a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# figure 1: show all cases on a world map\n",
    "\n",
    "# setup all the imports\n",
    "import matplotlib.font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs  # noqa: E402\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "flist = matplotlib.font_manager.get_font_names()\n",
    "from pathlib import Path  # noqa: E402\n",
    "\n",
    "from extremeweatherbench import evaluate, utils, cases, defaults, inputs, metrics, regions\n",
    "\n",
    "# make the basepath - change this to your local path\n",
    "basepath = Path.home() / \"ExtremeWeatherBench\" / \"\"\n",
    "basepath = str(basepath) + \"/\"\n",
    "\n",
    "# ugly hack to load in our plotting scripts\n",
    "import sys  # noqa: E402\n",
    "\n",
    "sys.path.append(basepath + \"/docs/notebooks/\")\n",
    "import paper_plotting as pp  # noqa: E402\n",
    "\n",
    "# load in all of the events in the yaml file\n",
    "print(\"loading in the events yaml file\")\n",
    "ewb_cases = cases.load_ewb_events_yaml_into_case_collection()\n",
    "# build out all of the expected data to evalate the case\n",
    "# this will not be a 1-1 mapping with ewb_cases because there are multiple data sources\n",
    "# to evaluate for some cases\n",
    "# for example, a heat/cold case will have both a case operator for ERA-5 data and GHCN\n",
    "case_operators = cases.build_case_operators(\n",
    "    ewb_cases, defaults.get_brightband_evaluation_objects()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd7b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a global color palatte so things are consistent across plots\n",
    "sns_palette = sns.color_palette(\"tab10\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "accessible_colors = [\n",
    "    \"#3394D6\",  # blue\n",
    "    \"#E09000\",  #  orange \"#E69F00\",  # orange\n",
    "    \"#A15A7E\",  # \"#CC79A7\",  # reddish purple\n",
    "    \"#CC4A4A\",  #  vermillion\"#D55E00\",  # vermillion\n",
    "    \"#A0A0A0\",  # Grey \"#000000\",  # black\n",
    "    \"#B2B24D\",  # Olive\n",
    "    \"#33B890\",  # bluish green\n",
    "    \"#78C6F1\",  # sky blue\n",
    "    \"#F0E442\",  # yellow\n",
    "]\n",
    "\n",
    "# defaults for plotting\n",
    "fourv2_style = {'color': accessible_colors[0]}\n",
    "gc_style = {'color': accessible_colors[2]}\n",
    "pangu_style = {'color': accessible_colors[3]}\n",
    "hres_style = {'color': 'black'}\n",
    "\n",
    "# the group styles and settings so that we can just easily grab them for the plots and they are globally consistent\n",
    "\n",
    "ghcn_group_style = {'linestyle':'-', 'marker':'o', 'group':'GHCN'}\n",
    "era5_group_style = {'linestyle':'--', 'marker':'s', 'group':'ERA5'}\n",
    "\n",
    "ifs_group_style = {'linestyle':'-', 'marker':'o', 'group':'IFS'}\n",
    "gfs_group_style = {'linestyle':':', 'marker':'d', 'group':'GFS'}\n",
    "\n",
    "global_group_style = {'linestyle':'--', 'marker':'*', 'group':'Global'}\n",
    "\n",
    "hres_group_style = {'linestyle':'-', 'marker':'.', 'group':'HRES'}\n",
    "\n",
    "# settings for the different models\n",
    "fourv2_ifs_cira_settings = {'forecast_source':'CIRA FOURv2 IFS', 'label_str': 'ForecastNet V2'} \n",
    "fourv2_gfs_cira_settings = {'forecast_source':'CIRA FOURv2 GFS', 'label_str': 'ForecastNet V2'} \n",
    "gc_ifs_cira_settings = {'forecast_source':'CIRA GC IFS', 'label_str': 'GraphCast'} \n",
    "gc_gfs_cira_settings = {'forecast_source':'CIRA GC GFS', 'label_str': 'GraphCast'} \n",
    "pangu_ifs_cira_settings = {'forecast_source':'CIRA PANG IFS', 'label_str': 'Pangu Weather'} \n",
    "pangu_gfs_cira_settings = {'forecast_source':'CIRA PANG GFS', 'label_str': 'Pangu Weather'} \n",
    "\n",
    "hres_ifs_settings = {'forecast_source':'ECMWF HRES', 'label_str': 'HRES'} \n",
    "\n",
    "fourv2_ifs_settings = fourv2_ifs_cira_settings | fourv2_style | ifs_group_style\n",
    "gc_ifs_settings = gc_ifs_cira_settings | gc_style | ifs_group_style\n",
    "pangu_ifs_settings = pangu_ifs_cira_settings | pangu_style | ifs_group_style\n",
    "hres_settings = hres_ifs_settings | hres_style | hres_group_style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad7d1d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results back in\n",
    "fourv2_heat_results = pd.read_pickle(basepath + 'docs/notebooks/figs/fourv2_heat_results.pkl')\n",
    "pang_heat_results = pd.read_pickle(basepath + 'docs/notebooks/figs/pang_heat_results.pkl')\n",
    "hres_heat_results = pd.read_pickle(basepath + 'docs/notebooks/figs/hres_heat_results.pkl')\n",
    "gc_heat_results = pd.read_pickle(basepath + 'docs/notebooks/figs/gc_heat_results.pkl')\n",
    "\n",
    "\n",
    "fourv2_freeze_results = pd.read_pickle(basepath + 'docs/notebooks/figs/fourv2_freeze_results.pkl')\n",
    "pang_freeze_results = pd.read_pickle(basepath + 'docs/notebooks/figs/pang_freeze_results.pkl')\n",
    "hres_freeze_results = pd.read_pickle(basepath + 'docs/notebooks/figs/hres_freeze_results.pkl')\n",
    "gc_freeze_results = pd.read_pickle(basepath + 'docs/notebooks/figs/gc_freeze_results.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cda639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot north american cases\n",
    "# North America\n",
    "na_bounding_box = [-172, -45, 7, 85]\n",
    "na_bounding_box_polygon = pp.get_polygon_from_bounding_box(na_bounding_box)\n",
    "na_bounding_region = regions.BoundingBoxRegion(latitude_min=7, latitude_max=85, longitude_min=-172, longitude_max=-45)\n",
    "\n",
    "# Europe\n",
    "eu_bounding_box = [50, -15, 15, 75]\n",
    "eu_bounding_box_polygon = pp.get_polygon_from_bounding_box(eu_bounding_box)\n",
    "eu_bounding_region = regions.BoundingBoxRegion(latitude_min=50, latitude_max=75, longitude_min=-15, longitude_max=15)\n",
    "\n",
    "# break the cases into different lists\n",
    "na_subset = regions.RegionSubsetter(region=na_bounding_region, method='intersects').subset_case_collection(ewb_cases)\n",
    "eu_subset = regions.RegionSubsetter(region=eu_bounding_region, method='intersects').subset_case_collection(ewb_cases)\n",
    "\n",
    "na_case_ids = [n.case_id_number for n in na_subset.cases]\n",
    "eu_case_ids = [n.case_id_number for n in eu_subset.cases]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34abd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean(results_df, forecast_source, target_source, metric, init_time, lead_times, case_ids=None):\n",
    "    subset = pp.subset_results_to_xarray(results_df=results_df, forecast_source=forecast_source, target_source=target_source, metric=metric, init_time=init_time, case_id_list=case_ids)\n",
    "    subset = subset.sel(lead_time=lead_times)\n",
    "    return subset[\"value\"].mean(dim='case_id_number').values\n",
    "\n",
    "def get_relative_error(results_df, hres_results, forecast_source, target_source, metric, init_time, lead_time_days, case_ids=None):\n",
    "    # down-select to just a few lead-times\n",
    "    lead_times = [np.timedelta64(lead_time_days[i], \"D\") for i in range(len(lead_time_days))]\n",
    "    my_mean = get_mean(results_df, forecast_source, target_source, metric, init_time, lead_times, case_ids)\n",
    "    hres_mean = get_mean(hres_results, hres_ifs_settings['forecast_source'], target_source, metric, init_time, lead_times, case_ids)\n",
    "    my_relative_error = (my_mean - hres_mean) / hres_mean * 100\n",
    "    \n",
    "    return (my_mean, my_relative_error)\n",
    "\n",
    "def get_error_array_for_heatmap(results_array, hres_results, forecast_sources, target_source, metric_strs, init_time, lead_time_days):\n",
    "    \"\"\"\n",
    "    This function takes in an array of results and parameters to say which results to grab and returns \n",
    "    error arrays and relative arrays for global, north america, and europe.\n",
    "    \"\"\"\n",
    "    # now make the array for the scorecard\n",
    "    global_rel_error = {}\n",
    "    global_error = {}\n",
    "\n",
    "    na_rel_error = {}\n",
    "    na_error = {}\n",
    "\n",
    "    eu_rel_error = {}\n",
    "    eu_error = {}\n",
    "\n",
    "\n",
    "    for metric in metric_strs:\n",
    "        # initialize the arrays\n",
    "        global_rel_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "        global_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "\n",
    "        na_rel_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "        na_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "\n",
    "        eu_rel_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "        eu_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "\n",
    "        for i, results_df in enumerate(results_array):\n",
    "            my_mean, my_relative_error = get_relative_error(results_df, hres_results, forecast_sources[i], target_source, metric, init_time, lead_time_days)\n",
    "            global_error[metric][i, :] = my_mean\n",
    "            global_rel_error[metric][i, :] = my_relative_error\n",
    "\n",
    "            na_mean, na_relative_error = get_relative_error(results_df, hres_results, forecast_source[i], target_source, metric, init_time, lead_time_days, case_ids=na_case_ids)\n",
    "            na_error[metric][i, :] = na_mean\n",
    "            na_rel_error[metric][i, :] = na_relative_error\n",
    "\n",
    "            eu_mean, eu_relative_error = get_relative_error(results_df, hres_results, forecast_sources[i], target_source, metric, init_time, lead_time_days, case_ids=eu_case_ids)\n",
    "            eu_error[metric][i, :] = eu_mean\n",
    "            eu_rel_error[metric][i, :] = eu_relative_error\n",
    "\n",
    "\n",
    "    return global_error, global_rel_error, na_error, na_rel_error, eu_error, eu_rel_error\n",
    "\n",
    "# setup for the scorecard\n",
    "# Grab means for each metric for each model\n",
    "heat_metric_str = ['maximum_mae', 'rmse', 'max_min_mae']\n",
    "freeze_metric_str = ['minimum_mae', 'rmse']\n",
    "heat_display_str = ['Maximum MAE', 'RMSE', 'Maximum MAE of Minimum Temperature']\n",
    "freeze_display_str = ['Minimum MAE', 'RMSE']\n",
    "\n",
    "lead_time_days = [1, 3, 5, 7, 10]\n",
    "\n",
    "heat_results_array = [hres_heat_results, fourv2_heat_results, gc_heat_results, pang_heat_results]\n",
    "forecast_source = [hres_ifs_settings['forecast_source'], fourv2_ifs_settings['forecast_source'], gc_ifs_settings['forecast_source'], pangu_ifs_settings['forecast_source']]\n",
    "freeze_results_array = [hres_freeze_results, fourv2_freeze_results, gc_freeze_results, pang_freeze_results]\n",
    "\n",
    "(global_heat_error, global_rel_heat_error, na_heat_error, na_rel_heat_error, eu_heat_error, eu_rel_heat_error) = \\\n",
    "    get_error_array_for_heatmap(heat_results_array, hres_heat_results, forecast_source, 'GHCN', heat_metric_str, 'zeroz', lead_time_days)\n",
    "(global_freeze_error, global_rel_freeze_error, na_freeze_error, na_rel_freeze_error, eu_freeze_error, eu_rel_freeze_error) = \\\n",
    "    get_error_array_for_heatmap(freeze_results_array, hres_freeze_results, forecast_source, 'GHCN', freeze_metric_str, 'zeroz', lead_time_days)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f126008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec\n",
    "\n",
    "n_rows = 6\n",
    "n_cols = 2\n",
    "figsize = (15 * n_cols, 6 * n_rows)\n",
    "print(figsize)\n",
    "\n",
    "# Create figure first\n",
    "fig = plt.figure(figsize=figsize)\n",
    "\n",
    "# Use GridSpec for better control over subplot sizes, especially with mixed cartopy/regular subplots\n",
    "# Make column 2 wider for line plots (width_ratios: col0, col1, col2)\n",
    "# Use negative hspace to compress vertical spacing (negative values allow overlap)\n",
    "gs = GridSpec(n_rows, n_cols, figure=fig, \n",
    "              left=0.05, right=0.95, top=0.98, bottom=0.02,\n",
    "              wspace=0.1, hspace=0.2,  \n",
    "              width_ratios=[1, 1])  # Make column 2 (index 2) 1.5x wider\n",
    "\n",
    "# Create a grid of subplots - specify which ones should use cartopy\n",
    "# Example: cartopy_subplots = [(0, 0), (1, 0)] means rows 0,1 in column 0 use cartopy\n",
    "# You can modify this list to specify which subplots need cartopy projections\n",
    "cartopy_subplots = [(0,0), (1,0), (2,0), (3,0), (4,0), (5,0)]  # Add tuples like (row, col) for subplots that need cartopy\n",
    "\n",
    "# Create all subplots\n",
    "axs = []\n",
    "for i in range(n_rows):\n",
    "    row = []\n",
    "    for j in range(n_cols):\n",
    "        if (i, j) in cartopy_subplots:\n",
    "            # Create cartopy subplot\n",
    "            ax = fig.add_subplot(gs[i, j], projection=ccrs.PlateCarree())\n",
    "        else:\n",
    "            # Create regular matplotlib subplot\n",
    "            ax = fig.add_subplot(gs[i, j])\n",
    "        row.append(ax)\n",
    "    axs.append(row)\n",
    "\n",
    "# Convert to numpy array for easier indexing (matching plt.subplots behavior)\n",
    "axs = np.array(axs)\n",
    "\n",
    "# the left hand column of figure one shows all of the cases for each event type\n",
    "# plot the cases for each event type\n",
    "print(\"plotting the cases for each event type\")\n",
    "pp.plot_all_cases(\n",
    "    ewb_cases,\n",
    "    event_type=\"heat_wave\",\n",
    "    fill_boxes=True,\n",
    "    ax=axs[0, 0],\n",
    ")\n",
    "\n",
    "# plot the cases for north america\n",
    "pp.plot_all_cases(ewb_cases, event_type='heat_wave', bounding_box=na_bounding_box, \n",
    "               fill_boxes=True, ax=axs[1, 0])\n",
    "\n",
    "# plot the cases for europe\n",
    "pp.plot_all_cases(ewb_cases, event_type='heat_wave', bounding_box=eu_bounding_box, \n",
    "               fill_boxes=True, ax=axs[2, 0])\n",
    "\n",
    "\n",
    "# do the same for the freeze cases\n",
    "pp.plot_all_cases(\n",
    "    ewb_cases,\n",
    "    event_type=\"freeze\",\n",
    "    fill_boxes=True,\n",
    "    ax=axs[3, 0],\n",
    ")\n",
    "\n",
    "pp.plot_all_cases(\n",
    "    ewb_cases,\n",
    "    event_type=\"freeze\",\n",
    "    bounding_box=na_bounding_box,\n",
    "    fill_boxes=True,\n",
    "    ax=axs[4, 0],\n",
    ")\n",
    "\n",
    "pp.plot_all_cases(\n",
    "    ewb_cases,\n",
    "    event_type=\"freeze\",\n",
    "    bounding_box=eu_bounding_box,\n",
    "    fill_boxes=True,\n",
    "    ax=axs[5, 0],\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "heat_settings = {}\n",
    "heat_settings[\"subplot_titles\"] = heat_display_str\n",
    "heat_settings[\"metric_str\"] = heat_metric_str\n",
    "heat_settings[\"lead_time_days\"] = lead_time_days\n",
    "heat_settings[\"model_order\"] = [\"HRES IFS\", \"FourvCastNet v2\", \"GraphCast\", \"Pangu\"]\n",
    "\n",
    "freeze_settings = {}\n",
    "freeze_settings[\"subplot_titles\"] = freeze_display_str\n",
    "freeze_settings[\"metric_str\"] = freeze_metric_str\n",
    "freeze_settings[\"lead_time_days\"] = lead_time_days\n",
    "freeze_settings[\"model_order\"] = [\"HRES IFS\", \"FourvCastNet v2\", \"GraphCast\", \"Pangu\"]\n",
    "\n",
    "# second column of figure 2 shows the scorecard\n",
    "pp.plot_heatmap(\n",
    "    global_rel_heat_error,\n",
    "    global_heat_error,\n",
    "    heat_settings,\n",
    "    ax=axs[0, 1],\n",
    ")\n",
    "\n",
    "pp.plot_heatmap(\n",
    "    na_rel_heat_error,\n",
    "    na_heat_error,\n",
    "    heat_settings,\n",
    "    ax=axs[1, 1],\n",
    ")\n",
    "\n",
    "pp.plot_heatmap(\n",
    "    eu_rel_heat_error,\n",
    "    eu_heat_error,\n",
    "    heat_settings,\n",
    "    ax=axs[2, 1],)\n",
    "\n",
    "pp.plot_heatmap(\n",
    "    global_rel_freeze_error,\n",
    "    global_freeze_error,\n",
    "    freeze_settings,\n",
    "    ax=axs[3, 1],\n",
    ")\n",
    "\n",
    "pp.plot_heatmap(\n",
    "    na_rel_freeze_error,\n",
    "    na_freeze_error,\n",
    "    freeze_settings,\n",
    "    ax=axs[4, 1],\n",
    ")\n",
    "\n",
    "pp.plot_heatmap(\n",
    "    eu_rel_freeze_error,\n",
    "    eu_freeze_error,\n",
    "    freeze_settings,\n",
    "    ax=axs[5, 1],\n",
    ")\n",
    "#fig.subplots_adjust(hspace=0.0)  # Set hspace to 0 to remove all vertical spacing\n",
    "\n",
    "fig.savefig(basepath + \"docs/notebooks/figs/figure2.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c8ef7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second column of figure 2 shows the scorecard\n",
    "pp.plot_heatmap(\n",
    "    global_rel_heat_error,\n",
    "    global_heat_error,\n",
    "    heat_settings,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
