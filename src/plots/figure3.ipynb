{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeeb2c0a",
   "metadata": {},
   "source": [
    "# Figure 3 notebook - this focuses on severe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09946de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup all the imports\n",
    "import matplotlib.font_manager\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs  # noqa: E402\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "flist = matplotlib.font_manager.get_font_names()\n",
    "from pathlib import Path  # noqa: E402\n",
    "\n",
    "from extremeweatherbench import evaluate, calc, cases, defaults, inputs, metrics, regions, derived, utils\n",
    "\n",
    "# make the basepath - change this to your local path\n",
    "basepath = Path.home() / \"extreme-weather-bench-paper\" / \"\"\n",
    "basepath = str(basepath) + \"/\"\n",
    "\n",
    "# ugly hack to load in our plotting scripts\n",
    "# import sys  # noqa: E402\n",
    "\n",
    "#sys.path.append(basepath + \"/docs/notebooks/\")\n",
    "import src.plots.plotting_utils as plot_utils  # noqa: E402\n",
    "import src.plots.results_utils as results_utils  # noqa: E402\n",
    "import src.plots.severe_convection_utils as severe_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1247b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# load in all of the events in the yaml file\n",
    "print(\"loading in the events yaml file\")\n",
    "ewb_cases = cases.load_ewb_events_yaml_into_case_collection()\n",
    "\n",
    "# downselect to only the severe cases\n",
    "ewb_cases = ewb_cases.select_cases(\"event_type\", \"severe_convection\")\n",
    "\n",
    "# build out all of the expected data to evalate the case (we need this so we can plot\n",
    "# the LSR reports)\n",
    "case_operators = cases.build_case_operators(\n",
    "    ewb_cases, defaults.get_brightband_evaluation_objects()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2105997f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to plot the targets, we need to run the pipeline for each case and target\n",
    "from joblib import Parallel, delayed  # noqa: E402\n",
    "from joblib.externals.loky import get_reusable_executor  # noqa: E402\n",
    "\n",
    "# load in all the case info (note this takes awhile in non-parallel form as it has to\n",
    "# run all the target information for each case)\n",
    "# this will return a list of tuples with the case id and the target dataset\n",
    "\n",
    "print(\"running the pipeline for each case and target\")\n",
    "parallel = Parallel(n_jobs=32, return_as=\"generator\", backend=\"loky\")\n",
    "case_operators_with_targets_established_generator = parallel(\n",
    "    delayed(\n",
    "        lambda co: (\n",
    "            co.case_metadata.case_id_number,\n",
    "            evaluate.run_pipeline(co.case_metadata, co.target),\n",
    "        )\n",
    "    )(case_operator)\n",
    "    for case_operator in case_operators\n",
    ")\n",
    "case_operators_with_targets_established = list(\n",
    "    case_operators_with_targets_established_generator\n",
    ")\n",
    "# this will throw a bunch of errors below but they're not consequential. this releases\n",
    "# the memory as it shuts down the workers\n",
    "get_reusable_executor().shutdown(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9fe21d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a global color palatte so things are consistent across plots\n",
    "sns_palette = sns.color_palette(\"tab10\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "accessible_colors = [\n",
    "    \"#3394D6\",  # blue\n",
    "    \"#E09000\",  #  orange \"#E69F00\",  # orange\n",
    "    \"#A15A7E\",  # \"#CC79A7\",  # reddish purple\n",
    "    \"#CC4A4A\",  #  vermillion\"#D55E00\",  # vermillion\n",
    "    \"#A0A0A0\",  # Grey \"#000000\",  # black\n",
    "    \"#B2B24D\",  # Olive\n",
    "    \"#33B890\",  # bluish green\n",
    "    \"#78C6F1\",  # sky blue\n",
    "    \"#F0E442\",  # yellow\n",
    "]\n",
    "\n",
    "# defaults for plotting\n",
    "fourv2_style = {'color': accessible_colors[0]}\n",
    "gc_style = {'color': accessible_colors[2]}\n",
    "pangu_style = {'color': accessible_colors[3]}\n",
    "hres_style = {'color': 'black'}\n",
    "\n",
    "# the group styles and settings so that we can just easily grab them for the plots and they are globally consistent\n",
    "\n",
    "ghcn_group_style = {'linestyle':'-', 'marker':'o', 'group':'GHCN'}\n",
    "era5_group_style = {'linestyle':'--', 'marker':'s', 'group':'ERA5'}\n",
    "\n",
    "ifs_group_style = {'linestyle':'-', 'marker':'o', 'group':'IFS'}\n",
    "gfs_group_style = {'linestyle':':', 'marker':'d', 'group':'GFS'}\n",
    "\n",
    "global_group_style = {'linestyle':'--', 'marker':'*', 'group':'Global'}\n",
    "\n",
    "hres_group_style = {'linestyle':'-', 'marker':'.', 'group':'HRES'}\n",
    "\n",
    "# settings for the different models\n",
    "fourv2_ifs_cira_settings = {'forecast_source':'CIRA FOURv2 IFS', 'label_str': 'ForecastNet V2'} \n",
    "fourv2_gfs_cira_settings = {'forecast_source':'CIRA FOURv2 GFS', 'label_str': 'ForecastNet V2'} \n",
    "gc_ifs_cira_settings = {'forecast_source':'CIRA GC IFS', 'label_str': 'GraphCast'} \n",
    "gc_gfs_cira_settings = {'forecast_source':'CIRA GC GFS', 'label_str': 'GraphCast'} \n",
    "pangu_ifs_cira_settings = {'forecast_source':'CIRA PANG IFS', 'label_str': 'Pangu Weather'} \n",
    "pangu_gfs_cira_settings = {'forecast_source':'CIRA PANG GFS', 'label_str': 'Pangu Weather'} \n",
    "\n",
    "hres_ifs_settings = {'forecast_source':'ECMWF HRES', 'label_str': 'HRES'} \n",
    "\n",
    "fourv2_ifs_settings = fourv2_ifs_cira_settings | fourv2_style | ifs_group_style\n",
    "gc_ifs_settings = gc_ifs_cira_settings | gc_style | ifs_group_style\n",
    "pangu_ifs_settings = pangu_ifs_cira_settings | pangu_style | ifs_group_style\n",
    "hres_settings = hres_ifs_settings | hres_style | hres_group_style\n",
    "\n",
    "fourv2_gfs_settings = fourv2_gfs_cira_settings | fourv2_style | gfs_group_style\n",
    "gc_gfs_settings = gc_gfs_cira_settings | gc_style | gfs_group_style\n",
    "pangu_gfs_settings = pangu_gfs_cira_settings | pangu_style | gfs_group_style\n",
    "\n",
    "severe_tp_settings = {'linestyle':'-', 'marker':'o', 'group':'True Positives'}\n",
    "severe_fn_settings = {'linestyle':'--', 'marker':'x', 'group':'False Negatives'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70ebd67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results back in\n",
    "fourv2_severe_results = pd.read_pickle(basepath + 'saved_data/fourv2_severe_results.pkl')\n",
    "pang_severe_results = pd.read_pickle(basepath + 'saved_data/pang_severe_results.pkl')\n",
    "hres_severe_results = pd.read_pickle(basepath + 'saved_data/hres_severe_results.pkl')\n",
    "gc_severe_results = pd.read_pickle(basepath + 'saved_data/gc_severe_results.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "431ded3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourv2_gfs_era5_settings_tp = fourv2_gfs_cira_settings | fourv2_style | severe_tp_settings \n",
    "gc_gfs_era5_settings_tp  = gc_gfs_cira_settings | gc_style | severe_tp_settings \n",
    "pangu_gfs_era5_settings_tp = pangu_gfs_cira_settings | pangu_style | severe_tp_settings \n",
    "hres_era5_settings_tp = hres_ifs_settings | hres_style | severe_tp_settings \n",
    "\n",
    "# grab the severe results\n",
    "fourv2_severe_plot_tp = results_utils.subset_results_to_xarray(results_df=fourv2_severe_results, \n",
    "    forecast_source=fourv2_gfs_cira_settings['forecast_source'], \n",
    "    target_source='local_storm_reports', metric='TruePositives', init_time='zeroz')\n",
    "gc_severe_plot_tp = results_utils.subset_results_to_xarray(results_df=gc_severe_results, \n",
    "    forecast_source=gc_gfs_cira_settings['forecast_source'], \n",
    "    target_source='local_storm_reports', metric='TruePositives', init_time='zeroz')\n",
    "pangu_severe_plot_tp  = results_utils.subset_results_to_xarray(results_df=pang_severe_results, \n",
    "    forecast_source=pangu_gfs_cira_settings['forecast_source'], \n",
    "    target_source='local_storm_reports', metric='TruePositives', init_time='zeroz')\n",
    "hres_severe_plot_tp = results_utils.subset_results_to_xarray(results_df=hres_severe_results, \n",
    "    forecast_source=hres_ifs_settings['forecast_source'], \n",
    "    target_source='local_storm_reports', metric='TruePositives', init_time='zeroz')\n",
    "\n",
    "# plot the results\n",
    "severe_data_tp = [gc_severe_plot_tp, pangu_severe_plot_tp, hres_severe_plot_tp, fourv2_severe_plot_tp]\n",
    "severe_settings_tp = [gc_gfs_era5_settings_tp, \n",
    "    pangu_gfs_era5_settings_tp, hres_era5_settings_tp, fourv2_gfs_era5_settings_tp]\n",
    "\n",
    "\n",
    "fourv2_gfs_era5_settings_fn = fourv2_gfs_cira_settings | fourv2_style | severe_fn_settings \n",
    "gc_gfs_era5_settings_fn  = gc_gfs_cira_settings | gc_style | severe_fn_settings \n",
    "pangu_gfs_era5_settings_fn = pangu_gfs_cira_settings | pangu_style | severe_fn_settings \n",
    "hres_era5_settings_fn = hres_ifs_settings | hres_style | severe_fn_settings \n",
    "print(gc_gfs_era5_settings_fn)\n",
    "\n",
    "# grab the results for the false negatives\n",
    "fourv2_severe_plot_fn = results_utils.subset_results_to_xarray(results_df=fourv2_severe_results, \n",
    "    forecast_source=fourv2_gfs_cira_settings['forecast_source'], \n",
    "    target_source='local_storm_reports', metric='FalseNegatives', init_time='zeroz')\n",
    "gc_severe_plot_fn = results_utils.subset_results_to_xarray(results_df=gc_severe_results, \n",
    "    forecast_source=gc_gfs_cira_settings['forecast_source'], \n",
    "    target_source='local_storm_reports', metric='FalseNegatives', init_time='zeroz')\n",
    "pangu_severe_plot_fn = results_utils.subset_results_to_xarray(results_df=pang_severe_results, \n",
    "    forecast_source=pangu_gfs_cira_settings['forecast_source'], \n",
    "    target_source='local_storm_reports', metric='FalseNegatives', init_time='zeroz')\n",
    "hres_severe_plot_fn = results_utils.subset_results_to_xarray(results_df=hres_severe_results, \n",
    "    forecast_source=hres_ifs_settings['forecast_source'], \n",
    "    target_source='local_storm_reports', metric='FalseNegatives', init_time='zeroz')\n",
    "\n",
    "# plot the results\n",
    "severe_data_fn = [gc_severe_plot_fn, pangu_severe_plot_fn, hres_severe_plot_fn, fourv2_severe_plot_fn]\n",
    "severe_settings_fn = [gc_gfs_era5_settings_fn, \n",
    "    pangu_gfs_era5_settings_fn, hres_era5_settings_fn, fourv2_gfs_era5_settings_fn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75a02af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the bounding boxes for the regions\n",
    "\n",
    "# North America\n",
    "na_bounding_box = [-172, -45, 7, 85]\n",
    "na_bounding_box_polygon = plot_utils.get_polygon_from_bounding_box(na_bounding_box)\n",
    "na_bounding_region = regions.BoundingBoxRegion(latitude_min=7, latitude_max=85, longitude_min=-172, longitude_max=-45)\n",
    "\n",
    "# australia bounding box\n",
    "au_bounding_box = [110, 180, -50, -10]\n",
    "au_bounding_box_polygon = plot_utils.get_polygon_from_bounding_box(au_bounding_box)\n",
    "au_bounding_region = regions.BoundingBoxRegion(latitude_min=-50, latitude_max=-10, longitude_min=110, longitude_max=180)\n",
    "\n",
    "# break the cases into different lists\n",
    "na_subset = regions.RegionSubsetter(region=na_bounding_region, method='intersects').subset_case_collection(ewb_cases)\n",
    "au_subset = regions.RegionSubsetter(region=au_bounding_region, method='intersects').subset_case_collection(ewb_cases)\n",
    "\n",
    "na_case_ids = [n.case_id_number for n in na_subset.cases]\n",
    "au_case_ids = [n.case_id_number for n in au_subset.cases]\n",
    "\n",
    "print(f'North America Cases: {na_case_ids}')\n",
    "print(f'Australia Cases: {au_case_ids}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96cb5755",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_array_for_heatmap(results_array, hres_results, forecast_sources, \n",
    "    target_source, metric_strs, init_time, lead_time_days, higher_is_better_list):\n",
    "    \"\"\"\n",
    "    This function takes in an array of results and parameters to say which results to grab and returns \n",
    "    error arrays and relative arrays for global, north america, and europe.\n",
    "    \"\"\"\n",
    "    # now make the array for the scorecard\n",
    "    global_rel_error = {}\n",
    "    global_error = {}\n",
    "\n",
    "    na_rel_error = {}\n",
    "    na_error = {}\n",
    "\n",
    "    au_rel_error = {}\n",
    "    au_error = {}\n",
    "\n",
    "\n",
    "    for i, metric in enumerate(metric_strs):\n",
    "        # initialize the arrays\n",
    "        global_rel_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "        global_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "\n",
    "        na_rel_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "        na_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "\n",
    "        au_rel_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "        au_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "\n",
    "        higher_is_better = higher_is_better_list[i]\n",
    "\n",
    "        for j, results_df in enumerate(results_array):\n",
    "            my_mean, my_relative_error = results_utils.compute_relative_error(results_df, \n",
    "                forecast_source=forecast_sources[j], \n",
    "                comparison_results_df=hres_results, \n",
    "                comparison_forecast_source=hres_settings['forecast_source'], \n",
    "                target_source=target_source, \n",
    "                metric=metric, init_time=init_time, lead_time_days=lead_time_days, \n",
    "                higher_is_better=higher_is_better)\n",
    "            global_error[metric][j, :] = my_mean\n",
    "            global_rel_error[metric][j, :] = my_relative_error\n",
    "\n",
    "            na_mean, na_relative_error = results_utils.compute_relative_error(results_df,\n",
    "                forecast_source=forecast_sources[j], \n",
    "                comparison_results_df=hres_results, \n",
    "                comparison_forecast_source=hres_settings['forecast_source'], \n",
    "                target_source=target_source, \n",
    "                metric=metric, init_time=init_time, lead_time_days=lead_time_days, \n",
    "                case_ids=na_case_ids, \n",
    "                higher_is_better=higher_is_better)\n",
    "            na_error[metric][j, :] = na_mean\n",
    "            na_rel_error[metric][j, :] = na_relative_error\n",
    "\n",
    "            au_mean, au_relative_error = results_utils.compute_relative_error(results_df,\n",
    "                forecast_source=forecast_sources[j], \n",
    "                comparison_results_df=hres_results, \n",
    "                comparison_forecast_source=hres_settings['forecast_source'], \n",
    "                target_source=target_source, \n",
    "                metric=metric, init_time=init_time, lead_time_days=lead_time_days, \n",
    "                case_ids=au_case_ids, \n",
    "                higher_is_better=higher_is_better)\n",
    "            au_error[metric][j, :] = au_mean\n",
    "            au_rel_error[metric][j, :] = au_relative_error\n",
    "\n",
    "\n",
    "    return global_error, global_rel_error, na_error, na_rel_error, au_error, au_rel_error\n",
    "\n",
    "# setup for the scorecard\n",
    "# Grab means for each metric for each model\n",
    "severe_metric_str = ['CriticalSuccessIndex', 'FalseAlarmRatio', 'EarlySignal']\n",
    "severe_display_str = ['Critical Success Index', 'False Alarm Ratio', 'Early Signal']\n",
    "severe_metric_higher_is_better = [True, False, True]\n",
    "target_source = 'practically_perfect_hindcast'\n",
    "\n",
    "lead_time_days = [1, 3, 5, 7, 10]\n",
    "\n",
    "severe_results_array = [hres_severe_results, gc_severe_results, \n",
    "    pang_severe_results, fourv2_severe_results]\n",
    "forecast_source = [hres_ifs_settings['forecast_source'], \n",
    "    gc_gfs_cira_settings['forecast_source'], \n",
    "    pangu_gfs_cira_settings['forecast_source'],\n",
    "    fourv2_gfs_cira_settings['forecast_source']]\n",
    "\n",
    "\n",
    "severe_results_array = [hres_severe_results, fourv2_severe_results, gc_severe_results, pang_severe_results]\n",
    "forecast_source = [hres_ifs_settings['forecast_source'], \n",
    "    fourv2_gfs_settings['forecast_source'], \n",
    "    gc_gfs_settings['forecast_source'], pangu_gfs_settings['forecast_source']]\n",
    "\n",
    "(global_severe_error, global_rel_severe_error, na_severe_error, na_rel_severe_error, au_severe_error, au_rel_severe_error) = \\\n",
    "    get_error_array_for_heatmap(severe_results_array, hres_severe_results, \n",
    "    forecast_source, 'practically_perfect_hindcast', severe_metric_str, 'zeroz', lead_time_days, severe_metric_higher_is_better )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56cf9b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cbss_and_pph_outputs(ewb_case, forecast_source):\n",
    "    pph_target = inputs.PPH()\n",
    "    pph = evaluate.run_pipeline(ewb_case,pph_target)\n",
    "    cbss = evaluate.run_pipeline(ewb_case,forecast_source)\n",
    "\n",
    "    return cbss, pph\n",
    "\n",
    "def get_pph_outputs(ewb_case, forecast_source):\n",
    "    pph_target = inputs.PPH()\n",
    "    pph = evaluate.run_pipeline(ewb_case,pph_target)\n",
    "    return pph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "57c2237c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "hres_graphics = pickle.load(open(basepath + \"saved_data/hres_graphics.pkl\", \"rb\"))\n",
    "gc_graphics = pickle.load(open(basepath + \"saved_data/gc_graphics.pkl\", \"rb\"))\n",
    "pang_graphics = pickle.load(open(basepath + \"saved_data/pang_graphics.pkl\", \"rb\"))\n",
    "fourv2_graphics = pickle.load(open(basepath + \"saved_data/fourv2_graphics.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d2b198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lsr_from_case_op(my_case, case_operators_with_targets_established):\n",
    "    for (id, case_info) in case_operators_with_targets_established:\n",
    "        if id == my_case.case_id_number:\n",
    "            if case_info.attrs[\"source\"] == \"local_storm_reports\":\n",
    "                return case_info\n",
    "   \n",
    "def plot_cbss_pph_panel(cbss, pph, my_case, lsrs, ax=None, title=None, lead_time_hours=0, gridlines_kwargs={}, geographic_features_kwargs={}):\n",
    "    my_bbox = dict()\n",
    "    my_bbox[\"latitude_min\"] = my_case.location.latitude_min\n",
    "    my_bbox[\"latitude_max\"] = my_case.location.latitude_max\n",
    "    my_bbox[\"longitude_min\"] = my_case.location.longitude_min\n",
    "    my_bbox[\"longitude_max\"] = my_case.location.longitude_max\n",
    "\n",
    "    # grab the valid time to plot\n",
    "    valid_time = cbss.craven_brooks_significant_severe.valid_time\n",
    "    my_pph = pph.sel(valid_time=valid_time).practically_perfect_hindcast.squeeze()\n",
    "\n",
    "    # grab the lsrs and convert to a dataframe\n",
    "    lsrs = lsrs.sel(valid_time=valid_time)\n",
    "    non_sparse_lsrs = utils.stack_dataarray_from_dims(\n",
    "                        lsrs[\"report_type\"], [\"latitude\", \"longitude\"]\n",
    "                    ).squeeze()\n",
    "    hail_data = non_sparse_lsrs[non_sparse_lsrs == 2]\n",
    "    tornado_data = non_sparse_lsrs[non_sparse_lsrs == 3]\n",
    "    hail_data = hail_data.to_dataframe().reset_index()\n",
    "    tornado_data = tornado_data.to_dataframe().reset_index()\n",
    "\n",
    "    ax, mappable = severe_utils.plot_cbss_forecast_panel(\n",
    "        cbss_data=cbss.craven_brooks_significant_severe.squeeze(),\n",
    "        target_date=my_case.start_date,\n",
    "        lead_time_hours=lead_time_hours,\n",
    "        bbox=my_bbox,\n",
    "        ax=ax,\n",
    "        pph_data=my_pph,\n",
    "        tornado_reports=tornado_data,\n",
    "        hail_reports=hail_data,\n",
    "        title=title,\n",
    "        alpha=0.6,\n",
    "        gridlines_kwargs=gridlines_kwargs,\n",
    "        geographic_features_kwargs=geographic_features_kwargs,\n",
    "    )\n",
    "    return ax, mappable\n",
    "\n",
    "def get_stats(results, forecast_source, my_case, lead_time_hours=0):\n",
    "    # list the statistics for each case\n",
    "    tp_all = results_utils.subset_results_to_xarray(results_df=results, \n",
    "        forecast_source=forecast_source, \n",
    "        target_source='local_storm_reports', metric='TruePositives', \n",
    "        init_time='zeroz', case_id_list=[my_case.case_id_number])\n",
    "\n",
    "    tp_mean = tp_all[\"value\"].mean(\"case_id_number\")\n",
    "    lead_time_td = pd.Timedelta(hours=lead_time_hours)\n",
    "    tp = tp_mean.sel(lead_time=lead_time_td, method=\"nearest\")\n",
    "\n",
    "    fn_all = results_utils.subset_results_to_xarray(results_df=results, \n",
    "        forecast_source=forecast_source, \n",
    "        target_source='local_storm_reports', metric='FalseNegatives', \n",
    "        init_time='zeroz', case_id_list=[my_case.case_id_number])\n",
    "\n",
    "    fn_mean = fn_all[\"value\"].mean(\"case_id_number\")\n",
    "    fn = fn_mean.sel(lead_time=lead_time_td, method=\"nearest\")\n",
    "    \n",
    "    csi_all = results_utils.subset_results_to_xarray(results_df=results, \n",
    "        forecast_source=forecast_source, \n",
    "        target_source='practically_perfect_hindcast', metric='CriticalSuccessIndex', \n",
    "        init_time='zeroz', case_id_list=[my_case.case_id_number])\n",
    "\n",
    "    csi_mean = csi_all[\"value\"].mean(\"case_id_number\")\n",
    "    csi = csi_mean.sel(lead_time=lead_time_td, method=\"nearest\")\n",
    "\n",
    "    far_all = results_utils.subset_results_to_xarray(results_df=results, \n",
    "        forecast_source=forecast_source, \n",
    "        target_source='practically_perfect_hindcast', metric='FalseAlarmRatio', \n",
    "        init_time='zeroz', case_id_list=[my_case.case_id_number])\n",
    "\n",
    "    far_mean = far_all[\"value\"].mean(\"case_id_number\")\n",
    "    far = far_mean.sel(lead_time=lead_time_td, method=\"nearest\")\n",
    "\n",
    "    es_all = results_utils.subset_results_to_xarray(results_df=results, \n",
    "        forecast_source=forecast_source, \n",
    "        target_source='practically_perfect_hindcast', metric='EarlySignal', \n",
    "        init_time='zeroz', case_id_list=[my_case.case_id_number])\n",
    "\n",
    "    es_mean = es_all[\"value\"].mean(\"case_id_number\")\n",
    "    es = es_mean.sel(lead_time=lead_time_td, method=\"nearest\")\n",
    "    \n",
    "    return [tp.values, fn.values, csi.values, far.values, es.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d279b19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_ids = [269, 270, 271, 284, 285, 286, 287, 288, 316, 317, 318, 319, 320, 321, 322, 323]\n",
    "my_ids = [269, 318]\n",
    "\n",
    "# plot all of the cases where we had all three models\n",
    "for my_id in my_ids:\n",
    "    print(my_id)\n",
    "    my_case = ewb_cases.select_cases(\"case_id_number\", my_id).cases[0]\n",
    "    my_lsr = get_lsr_from_case_op(my_case, case_operators_with_targets_established)\n",
    "    \n",
    "    cbss_hres, pph_hres = hres_graphics[my_id, \"cbss\"], hres_graphics[my_id, \"pph\"]\n",
    "    cbss_gc, pph_gc = gc_graphics[my_id, \"cbss\"], gc_graphics[my_id, \"pph\"]\n",
    "    cbss_pang, pph_pang = pang_graphics[my_id, \"cbss\"], pang_graphics[my_id, \"pph\"]\n",
    "    cbss_fourv2, pph_fourv2 = fourv2_graphics[my_id, \"cbss\"], fourv2_graphics[my_id, \"pph\"]\n",
    "\n",
    "    # make a subplot for each model and ensure it is a cartopy plot\n",
    "    fig, axs = plt.subplots(2, 4, figsize=(10, 4), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "    plot_cbss_pph_panel(cbss_hres, pph_hres, my_case, lsrs=my_lsr, ax=axs[0,0], title=\"HRES\", lead_time_hours=48)\n",
    "    plot_cbss_pph_panel(cbss_gc, pph_gc, my_case, lsrs=my_lsr, ax=axs[0,1], title=\"GraphCast\", lead_time_hours=48)\n",
    "    plot_cbss_pph_panel(cbss_pang, pph_pang, my_case, lsrs=my_lsr, ax=axs[0,2], title=\"Pangu\", lead_time_hours=48)\n",
    "    plot_cbss_pph_panel(cbss_fourv2, pph_fourv2, my_case, lsrs=my_lsr, ax=axs[0,3], title=\"FOURv2\", lead_time_hours=48)\n",
    "\n",
    "\n",
    "    # now plot the stats\n",
    "    [tp, fn, csi, far, es] = get_stats(hres_severe_results, \n",
    "        hres_ifs_settings['forecast_source'], my_case, lead_time_hours=48)\n",
    "\n",
    "    axs[1,0].text(0.5, 0.5, f\"CSI: {csi:.2f}\\n\"\n",
    "            f\"FAR: {far:.2f}\\n\"\n",
    "            f\"ES: {es:.2f}\\n\"\n",
    "            f\"TP: {tp:.2f}\\n\"\n",
    "            f\"FN: {fn:.2f}\",\n",
    "            transform=axs[1,0].transAxes,\n",
    "            ha='center', va='center')\n",
    "\n",
    "    [tp, fn, csi, far, es] = get_stats(gc_severe_results, \n",
    "        gc_gfs_cira_settings['forecast_source'], my_case, lead_time_hours=48)\n",
    "\n",
    "    axs[1,1].text(0.5, 0.5, f\"CSI: {csi:.2f}\\n\"\n",
    "            f\"FAR: {far:.2f}\\n\"\n",
    "            f\"ES: {es:.2f}\\n\"\n",
    "            f\"TP: {tp:.2f}\\n\"\n",
    "            f\"FN: {fn:.2f}\",\n",
    "            transform=axs[1,1].transAxes,\n",
    "            ha='center', va='center')\n",
    "\n",
    "    [tp, fn, csi, far, es] = get_stats(pang_severe_results, \n",
    "        pangu_gfs_cira_settings['forecast_source'], my_case, lead_time_hours=48)\n",
    "\n",
    "    axs[1,2].text(0.5, 0.5, f\"CSI: {csi:.2f}\\n\"\n",
    "            f\"FAR: {far:.2f}\\n\"\n",
    "            f\"ES: {es:.2f}\\n\"\n",
    "            f\"TP: {tp:.2f}\\n\"\n",
    "            f\"FN: {fn:.2f}\",\n",
    "            transform=axs[1,2].transAxes,\n",
    "            ha='center', va='center')\n",
    "\n",
    "    [tp, fn, csi, far, es] = get_stats(fourv2_severe_results, \n",
    "        fourv2_gfs_cira_settings['forecast_source'], my_case, lead_time_hours=48)\n",
    "\n",
    "    axs[1,3].text(0.5, 0.5, f\"CSI: {csi:.2f}\\n\"\n",
    "            f\"FAR: {far:.2f}\\n\"\n",
    "            f\"ES: {es:.2f}\\n\"\n",
    "            f\"TP: {tp:.2f}\\n\"\n",
    "            f\"FN: {fn:.2f}\",\n",
    "            transform=axs[1,3].transAxes,\n",
    "            ha='center', va='center')\n",
    "    \n",
    "\n",
    "    fig.suptitle(f\"Case {my_id}\")\n",
    "    fig.savefig(basepath + f\"saved_data/severe_case_{my_id}.png\", dpi=300, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00caedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "\n",
    "n_rows = 5\n",
    "n_cols_top = 2  # Columns for top 3 rows\n",
    "n_cols_bottom = 4  # Columns for bottom 2 rows (more Cartopy plots)\n",
    "figsize = (7.5 * max(n_cols_top, n_cols_bottom), 7 * n_rows)\n",
    "print(figsize)\n",
    "\n",
    "# Create figure first\n",
    "fig = plt.figure(figsize=figsize)\n",
    "\n",
    "# Main GridSpec: 5 rows, use max columns for layout\n",
    "# Top 3 rows will use 2 columns, bottom 2 rows will use 4 columns\n",
    "gs_main = GridSpec(n_rows, 1, figure=fig, \n",
    "                #    left=0.05, right=0.95, top=0.98, bottom=0.02,\n",
    "                   hspace=0.75)\n",
    "\n",
    "# Create subplots for top 3 rows (2 columns each)\n",
    "gs_top = GridSpecFromSubplotSpec(3, n_cols_top, subplot_spec=gs_main[0:3, 0],\n",
    "                                  wspace=0.02, hspace=0.2,\n",
    "                                  width_ratios=[1, 1])\n",
    "\n",
    "# Create subplots for bottom 2 rows (4 columns each - all Cartopy)\n",
    "gs_bottom = GridSpecFromSubplotSpec(2, n_cols_bottom, subplot_spec=gs_main[3:5, 0],\n",
    "                                     wspace=0.15, hspace=0.05)\n",
    "\n",
    "# Create all subplots - initialize as array with shape (n_rows, max_cols)\n",
    "max_cols = max(n_cols_top, n_cols_bottom)\n",
    "axs = np.empty((n_rows, max_cols), dtype=object)\n",
    "\n",
    "# Top 3 rows: 2 columns (Cartopy on left, regular on right)\n",
    "for i in range(3):\n",
    "    # Left column: Cartopy\n",
    "    ax_cartopy = fig.add_subplot(gs_top[i, 0], projection=ccrs.PlateCarree())\n",
    "    axs[i,0] = ax_cartopy\n",
    "\n",
    "    # Right column: Regular matplotlib\n",
    "    ax_regular = fig.add_subplot(gs_top[i, 1])\n",
    "    axs[i,1] = ax_regular\n",
    "\n",
    "# Bottom 2 rows: 4 columns (all Cartopy)\n",
    "for i in range(2):\n",
    "    for j in range(n_cols_bottom):\n",
    "        ax_cartopy = fig.add_subplot(gs_bottom[i, j], projection=ccrs.PlateCarree())\n",
    "        axs[i+3,j] = ax_cartopy\n",
    "\n",
    "\n",
    "# the left hand column of figure one shows all of the cases for each event type\n",
    "# plot the cases for each event type\n",
    "print(\"plotting the cases for each event type\")\n",
    "plot_utils.plot_all_cases_and_obs(\n",
    "    ewb_cases,\n",
    "    event_type=\"severe_convection\",\n",
    "    targets=case_operators_with_targets_established,\n",
    "    ax=axs[0, 0],\n",
    ")\n",
    "# plot the cases for north america\n",
    "plot_utils.plot_all_cases_and_obs(\n",
    "    ewb_cases,\n",
    "    event_type=\"severe_convection\",\n",
    "    targets=case_operators_with_targets_established,\n",
    "    bounding_box=na_bounding_box,\n",
    "    ax=axs[1, 0],\n",
    ")\n",
    "\n",
    "# plot the cases for australia\n",
    "plot_utils.plot_all_cases_and_obs(\n",
    "    ewb_cases,\n",
    "    event_type=\"severe_convection\",\n",
    "    targets=case_operators_with_targets_established,\n",
    "    bounding_box=au_bounding_box,\n",
    "    ax=axs[2, 0],\n",
    ")\n",
    "\n",
    "\n",
    "severe_settings = {}\n",
    "severe_settings[\"subplot_titles\"] = severe_display_str\n",
    "severe_settings[\"metric_str\"] = severe_metric_str\n",
    "severe_settings[\"lead_time_days\"] = lead_time_days\n",
    "severe_settings[\"model_order\"] = [\"HRES IFS\", \"GraphCast\", \"Pangu\", \"FourCastNet v2\"]\n",
    "\n",
    "# second column of figure 2 shows the scorecard\n",
    "plot_utils.plot_heatmap(\n",
    "    global_rel_severe_error,\n",
    "    global_severe_error,\n",
    "    severe_settings,\n",
    "    ax=axs[0, 1],\n",
    ")\n",
    "\n",
    "plot_utils.plot_heatmap(\n",
    "    na_rel_severe_error,\n",
    "    na_severe_error,\n",
    "    severe_settings,\n",
    "    ax=axs[1, 1],\n",
    ")\n",
    "\n",
    "plot_utils.plot_heatmap(\n",
    "    au_rel_severe_error,\n",
    "    au_severe_error,\n",
    "    severe_settings,\n",
    "    ax=axs[2, 1],\n",
    "    show_colorbar=True,\n",
    ")\n",
    "\n",
    "\n",
    "# in the 4th row, plot the cbss and pph for all the models\n",
    "my_id = 318\n",
    "my_case = ewb_cases.select_cases(\"case_id_number\", my_id).cases[0]\n",
    "my_lsr = get_lsr_from_case_op(my_case, case_operators_with_targets_established)\n",
    "\n",
    "cbss_hres, pph_hres = hres_graphics[my_id, \"cbss\"], hres_graphics[my_id, \"pph\"]\n",
    "cbss_gc, pph_gc = gc_graphics[my_id, \"cbss\"], gc_graphics[my_id, \"pph\"]\n",
    "cbss_pang, pph_pang = pang_graphics[my_id, \"cbss\"], pang_graphics[my_id, \"pph\"]\n",
    "cbss_fourv2, pph_fourv2 = fourv2_graphics[my_id, \"cbss\"], fourv2_graphics[my_id, \"pph\"]\n",
    "\n",
    "plot_cbss_pph_panel(cbss_hres, pph_hres, my_case, lsrs=my_lsr, ax=axs[3, 0], title=\"HRES\", lead_time_hours=48)\n",
    "plot_cbss_pph_panel(cbss_gc, pph_gc, my_case, lsrs=my_lsr, ax=axs[3, 1], title=\"GraphCast\", lead_time_hours=48)\n",
    "plot_cbss_pph_panel(cbss_pang, pph_pang, my_case, lsrs=my_lsr, ax=axs[3, 2], title=\"Pangu\", lead_time_hours=48)\n",
    "plot_cbss_pph_panel(cbss_fourv2, pph_fourv2, my_case, lsrs=my_lsr, ax=axs[3, 3], title=\"FourCastNet v2\", lead_time_hours=48)\n",
    "\n",
    "# # the bottom row will be australia but we are plotting NA until AUS works\n",
    "# # in the 4th row, plot the cbss and pph for all the models\n",
    "my_id = 269\n",
    "my_case = ewb_cases.select_cases(\"case_id_number\", my_id).cases[0]\n",
    "my_lsr = get_lsr_from_case_op(my_case, case_operators_with_targets_established)\n",
    "\n",
    "cbss_hres, pph_hres = hres_graphics[my_id, \"cbss\"], hres_graphics[my_id, \"pph\"]\n",
    "cbss_gc, pph_gc = gc_graphics[my_id, \"cbss\"], gc_graphics[my_id, \"pph\"]\n",
    "cbss_pang, pph_pang = pang_graphics[my_id, \"cbss\"], pang_graphics[my_id, \"pph\"]\n",
    "cbss_fourv2, pph_fourv2 = fourv2_graphics[my_id, \"cbss\"], fourv2_graphics[my_id, \"pph\"]\n",
    "\n",
    "plot_cbss_pph_panel(cbss_hres, pph_hres, my_case, lsrs=my_lsr, ax=axs[4, 0], title=\"HRES\", lead_time_hours=48)\n",
    "plot_cbss_pph_panel(cbss_gc, pph_gc, my_case, lsrs=my_lsr, ax=axs[4, 1], title=\"GraphCast\", lead_time_hours=48)\n",
    "plot_cbss_pph_panel(cbss_pang, pph_pang, my_case, lsrs=my_lsr, ax=axs[4, 2], title=\"Pangu\", lead_time_hours=48)\n",
    "plot_cbss_pph_panel(cbss_fourv2, pph_fourv2, my_case, lsrs=my_lsr, ax=axs[4, 3], title=\"FourCastNet v2\", lead_time_hours=48)\n",
    "\n",
    "# plt.savefig(basepath + \"saved_data/figure3.png\", dpi=600, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
