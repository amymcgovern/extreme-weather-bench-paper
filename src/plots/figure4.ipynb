{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eeeb2c0a",
   "metadata": {},
   "source": [
    "# Figure 4 notebook - this focuses on ARs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1834f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09946de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup all the imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from extremeweatherbench import evaluate, calc, cases, defaults, inputs, metrics, regions, derived\n",
    "sns.set_theme(style='whitegrid')\n",
    "import shapely\n",
    "from pathlib import Path\n",
    "import multiprocessing\n",
    "import xarray as xr\n",
    "from matplotlib.lines import Line2D\n",
    "import cartopy.crs as ccrs  # noqa: E402\n",
    "import datetime\n",
    "\n",
    "# make the basepath - change this to your local path\n",
    "basepath = Path.home() / \"extreme-weather-bench-paper\" / \"\"\n",
    "basepath = str(basepath) + \"/\"\n",
    "\n",
    "import src.plots.plotting_utils as plot_utils  # noqa: E402\n",
    "import src.plots.results_utils as results_utils  # noqa: E402\n",
    "import src.plots.atmospheric_river_utils as ar_plot_utils  # noqa: E402\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1247b5c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all of the events in the yaml file\n",
    "print(\"loading in the events yaml file\")\n",
    "ewb_cases = cases.load_ewb_events_yaml_into_case_collection()\n",
    "# build out all of the expected data to evalate the case\n",
    "# this will not be a 1-1 mapping with ewb_cases because there are multiple data sources\n",
    "# to evaluate for some cases\n",
    "# for example, a heat/cold case will have both a case operator for ERA-5 data and GHCN\n",
    "case_operators = cases.build_case_operators(\n",
    "    ewb_cases, defaults.get_brightband_evaluation_objects()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe21d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a global color palatte so things are consistent across plots\n",
    "sns_palette = sns.color_palette(\"tab10\")\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "accessible_colors = [\n",
    "    \"#3394D6\",  # blue\n",
    "    \"#E09000\",  #  orange \"#E69F00\",  # orange\n",
    "    \"#A15A7E\",  # \"#CC79A7\",  # reddish purple\n",
    "    \"#CC4A4A\",  #  vermillion\"#D55E00\",  # vermillion\n",
    "    \"#A0A0A0\",  # Grey \"#000000\",  # black\n",
    "    \"#B2B24D\",  # Olive\n",
    "    \"#33B890\",  # bluish green\n",
    "    \"#78C6F1\",  # sky blue\n",
    "    \"#F0E442\",  # yellow\n",
    "]\n",
    "\n",
    "# defaults for plotting\n",
    "fourv2_style = {'color': accessible_colors[0]}\n",
    "gc_style = {'color': accessible_colors[2]}\n",
    "pangu_style = {'color': accessible_colors[3]}\n",
    "hres_style = {'color': 'black'}\n",
    "\n",
    "# the group styles and settings so that we can just easily grab them for the plots and they are globally consistent\n",
    "\n",
    "ghcn_group_style = {'linestyle':'-', 'marker':'o', 'group':'GHCN'}\n",
    "era5_group_style = {'linestyle':'--', 'marker':'s', 'group':'ERA5'}\n",
    "\n",
    "ifs_group_style = {'linestyle':'-', 'marker':'o', 'group':'IFS'}\n",
    "gfs_group_style = {'linestyle':':', 'marker':'d', 'group':'GFS'}\n",
    "\n",
    "global_group_style = {'linestyle':'--', 'marker':'*', 'group':'Global'}\n",
    "\n",
    "hres_group_style = {'linestyle':'-', 'marker':'.', 'group':'HRES'}\n",
    "\n",
    "# settings for the different models\n",
    "fourv2_ifs_cira_settings = {'forecast_source':'CIRA FOURv2 IFS', 'label_str': 'ForecastNet V2'} \n",
    "fourv2_gfs_cira_settings = {'forecast_source':'CIRA FOURv2 GFS', 'label_str': 'ForecastNet V2'} \n",
    "gc_ifs_cira_settings = {'forecast_source':'CIRA GC IFS', 'label_str': 'GraphCast'} \n",
    "gc_gfs_cira_settings = {'forecast_source':'CIRA GC GFS', 'label_str': 'GraphCast'} \n",
    "pangu_ifs_cira_settings = {'forecast_source':'CIRA PANG IFS', 'label_str': 'Pangu Weather'} \n",
    "pangu_gfs_cira_settings = {'forecast_source':'CIRA PANG GFS', 'label_str': 'Pangu Weather'} \n",
    "\n",
    "hres_ifs_settings = {'forecast_source':'ECMWF HRES', 'label_str': 'HRES'} \n",
    "\n",
    "fourv2_ifs_settings = fourv2_ifs_cira_settings | fourv2_style | ifs_group_style\n",
    "gc_ifs_settings = gc_ifs_cira_settings | gc_style | ifs_group_style\n",
    "pangu_ifs_settings = pangu_ifs_cira_settings | pangu_style | ifs_group_style\n",
    "hres_settings = hres_ifs_settings | hres_style | hres_group_style\n",
    "\n",
    "fourv2_gfs_settings = fourv2_gfs_cira_settings | fourv2_style | gfs_group_style\n",
    "gc_gfs_settings = gc_gfs_cira_settings | gc_style | gfs_group_style\n",
    "pangu_gfs_settings = pangu_gfs_cira_settings | pangu_style | gfs_group_style\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ebd67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the results back in\n",
    "fourv2_ar_results = pd.read_pickle(basepath + 'saved_data/fourv2_ar_results.pkl')\n",
    "pang_ar_results = pd.read_pickle(basepath + 'saved_data/pang_ar_results.pkl')\n",
    "hres_ar_results = pd.read_pickle(basepath + 'saved_data/hres_ar_results.pkl')\n",
    "gc_ar_results = pd.read_pickle(basepath + 'saved_data/gc_ar_results.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431ded3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourv2_gfs_era5_settings_csi = fourv2_gfs_cira_settings | fourv2_style | era5_group_style   \n",
    "gc_gfs_era5_settings_csi  = gc_gfs_cira_settings | gc_style | era5_group_style\n",
    "pangu_gfs_era5_settings_csi = pangu_gfs_cira_settings | pangu_style | era5_group_style\n",
    "hres_era5_settings_csi = hres_ifs_settings | hres_style | hres_group_style\n",
    "\n",
    "# grab the ar CSI results\n",
    "fourv2_ar_plot_csi = results_utils.subset_results_to_xarray(results_df=fourv2_ar_results, \n",
    "    forecast_source=fourv2_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz')\n",
    "gc_ar_plot_csi = results_utils.subset_results_to_xarray(results_df=gc_ar_results, \n",
    "    forecast_source=gc_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz')\n",
    "pangu_ar_plot_csi  = results_utils.subset_results_to_xarray(results_df=pang_ar_results, \n",
    "    forecast_source=pangu_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz')\n",
    "hres_ar_plot_csi = results_utils.subset_results_to_xarray(results_df=hres_ar_results, \n",
    "    forecast_source=hres_era5_settings_csi['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz')\n",
    "\n",
    "# plot the results\n",
    "ar_data_csi = [fourv2_ar_plot_csi, gc_ar_plot_csi, pangu_ar_plot_csi, hres_ar_plot_csi]\n",
    "ar_settings_csi = [fourv2_gfs_era5_settings_csi, gc_gfs_era5_settings_csi, \n",
    "    pangu_gfs_era5_settings_csi, hres_era5_settings_csi]\n",
    "\n",
    "# grab the spatial displacement results\n",
    "fourv2_ar_plot_sd = results_utils.subset_results_to_xarray(results_df=fourv2_ar_results, \n",
    "    forecast_source=fourv2_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='spatial_displacement', init_time='zeroz')\n",
    "gc_ar_plot_sd = results_utils.subset_results_to_xarray(results_df=gc_ar_results, \n",
    "    forecast_source=gc_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='spatial_displacement', init_time='zeroz')\n",
    "pangu_ar_plot_sd  = results_utils.subset_results_to_xarray(results_df=pang_ar_results, \n",
    "    forecast_source=pangu_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='spatial_displacement', init_time='zeroz')\n",
    "hres_ar_plot_sd = results_utils.subset_results_to_xarray(results_df=hres_ar_results, \n",
    "    forecast_source=hres_era5_settings_csi['forecast_source'], \n",
    "    target_source='ERA5', metric='spatial_displacement', init_time='zeroz')\n",
    "\n",
    "ar_data_sd = [fourv2_ar_plot_sd, gc_ar_plot_sd, pangu_ar_plot_sd, hres_ar_plot_sd]\n",
    "ar_settings_sd = [fourv2_gfs_era5_settings_csi, gc_gfs_era5_settings_csi, \n",
    "    pangu_gfs_era5_settings_csi, hres_era5_settings_csi]\n",
    "\n",
    "# grab the early signal results\n",
    "# fourv2_ar_plot_es = pp.subset_results_to_xarray(results_df=fourv2_ar_results, \n",
    "#     forecast_source=fourv2_gfs_cira_settings['forecast_source'], \n",
    "#     target_source='ERA5', metric='EarlySignal', init_time='zeroz')\n",
    "# gc_ar_plot_es = pp.subset_results_to_xarray(results_df=gc_ar_results, \n",
    "#     forecast_source=gc_gfs_cira_settings['forecast_source'], \n",
    "#     target_source='ERA5', metric='EarlySignal', init_time='zeroz')\n",
    "# pangu_ar_plot_es  = pp.subset_results_to_xarray(results_df=pang_ar_results, \n",
    "#     forecast_source=pangu_gfs_cira_settings['forecast_source'], \n",
    "#     target_source='ERA5', metric='EarlySignal', init_time='zeroz')\n",
    "# hres_ar_plot_es = pp.subset_results_to_xarray(results_df=hres_ar_results, \n",
    "#     forecast_source=hres_era5_settings_csi['forecast_source'], \n",
    "#     target_source='ERA5', metric='EarlySignal', init_time='zeroz')\n",
    "\n",
    "# ar_data_es = [fourv2_ar_plot_es, gc_ar_plot_es, pangu_ar_plot_es, hres_ar_plot_es]\n",
    "# ar_settings_es = [fourv2_gfs_era5_settings_csi, gc_gfs_era5_settings_csi, \n",
    "#     pangu_gfs_era5_settings_csi, hres_era5_settings_csi]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a02af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the bounding boxes for the regions\n",
    "\n",
    "# North America\n",
    "na_bounding_box = [-172, -45, 7, 85]\n",
    "na_bounding_box_polygon = plot_utils.get_polygon_from_bounding_box(na_bounding_box)\n",
    "na_bounding_region = regions.BoundingBoxRegion(latitude_min=7, latitude_max=85, longitude_min=-172, longitude_max=-45)\n",
    "\n",
    "# europe bounding box\n",
    "eu_bounding_box = [-10, 35, 20, 70]\n",
    "eu_bounding_box_polygon = plot_utils.get_polygon_from_bounding_box(eu_bounding_box)\n",
    "eu_bounding_region = regions.BoundingBoxRegion(latitude_min=20, latitude_max=70, longitude_min=-10, longitude_max=35)\n",
    "\n",
    "# australia bounding box\n",
    "au_bounding_box = [110, 180, -50, -10]\n",
    "au_bounding_box_polygon = plot_utils.get_polygon_from_bounding_box(au_bounding_box)\n",
    "au_bounding_region = regions.BoundingBoxRegion(latitude_min=-50, latitude_max=-10, longitude_min=110, longitude_max=180)\n",
    "\n",
    "# break the cases into different lists\n",
    "na_subset = regions.RegionSubsetter(region=na_bounding_region, method='intersects').subset_case_collection(ewb_cases)\n",
    "au_subset = regions.RegionSubsetter(region=au_bounding_region, method='intersects').subset_case_collection(ewb_cases)\n",
    "eu_subset = regions.RegionSubsetter(region=eu_bounding_region, method='intersects').subset_case_collection(ewb_cases)\n",
    "na_case_ids = [n.case_id_number for n in na_subset.cases]\n",
    "au_case_ids = [n.case_id_number for n in au_subset.cases]\n",
    "eu_case_ids = [n.case_id_number for n in eu_subset.cases]\n",
    "\n",
    "print(f'North America Cases: {na_case_ids}')\n",
    "print(f'Australia Cases: {au_case_ids}')\n",
    "print(f'Europe Cases: {eu_case_ids}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9014303b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a group style for the local/global plots\n",
    "na_group_style = {'linestyle':'-', 'marker':'h', 'group':'North America'}\n",
    "au_group_style = {'linestyle':'-', 'marker':'h', 'group':'Australia'}\n",
    "eu_group_style = {'linestyle':'-', 'marker':'h', 'group':'Europe'}\n",
    "# plot the results for one metric for the three AI models versus HRES\n",
    "na_fourv2_gfs_settings = fourv2_gfs_cira_settings | fourv2_style | na_group_style\n",
    "na_gc_gfs_settings = gc_gfs_cira_settings | gc_style | na_group_style\n",
    "na_pangu_gfs_settings = pangu_gfs_cira_settings | pangu_style | na_group_style\n",
    "na_hres_settings = hres_ifs_settings | hres_style | na_group_style\n",
    "\n",
    "au_fourv2_gfs_settings = fourv2_gfs_cira_settings | fourv2_style | au_group_style\n",
    "au_gc_gfs_settings = gc_gfs_cira_settings | gc_style | au_group_style\n",
    "au_pangu_gfs_settings = pangu_gfs_cira_settings | pangu_style | au_group_style\n",
    "au_hres_settings = hres_ifs_settings | hres_style | au_group_style\n",
    "\n",
    "eu_fourv2_gfs_settings = fourv2_gfs_cira_settings | fourv2_style | eu_group_style\n",
    "eu_gc_gfs_settings = gc_gfs_cira_settings | gc_style | eu_group_style\n",
    "eu_pangu_gfs_settings = pangu_gfs_cira_settings | pangu_style | eu_group_style\n",
    "eu_hres_settings = hres_ifs_settings | hres_style | eu_group_style\n",
    "\n",
    "# subset the data for the plots\n",
    "na_fourv2_severe_plot_csi = results_utils.subset_results_to_xarray(results_df=fourv2_ar_results, \n",
    "    forecast_source=fourv2_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz',\n",
    "    case_id_list=na_case_ids)\n",
    "na_gc_severe_plot_csi = results_utils.subset_results_to_xarray(results_df=gc_ar_results, \n",
    "    forecast_source=gc_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz',\n",
    "    case_id_list=na_case_ids)\n",
    "na_pangu_severe_plot_csi  = results_utils.subset_results_to_xarray(results_df=pang_ar_results, \n",
    "    forecast_source=pangu_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz',\n",
    "    case_id_list=na_case_ids)\n",
    "na_hres_severe_plot_csi = results_utils.subset_results_to_xarray(results_df=hres_ar_results, \n",
    "    forecast_source=hres_ifs_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz',\n",
    "    case_id_list=na_case_ids)\n",
    "\n",
    "# subset the data for the plots\n",
    "au_fourv2_severe_plot_csi = results_utils.subset_results_to_xarray(results_df=fourv2_ar_results, \n",
    "    forecast_source=fourv2_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz',\n",
    "    case_id_list=au_case_ids)\n",
    "au_gc_severe_plot_csi = results_utils.subset_results_to_xarray(results_df=gc_ar_results, \n",
    "    forecast_source=gc_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz',\n",
    "    case_id_list=au_case_ids)\n",
    "au_pangu_severe_plot_csi  = results_utils.subset_results_to_xarray(results_df=pang_ar_results, \n",
    "    forecast_source=pangu_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz',\n",
    "    case_id_list=au_case_ids)\n",
    "au_hres_severe_plot_csi = results_utils.subset_results_to_xarray(results_df=hres_ar_results, \n",
    "    forecast_source=hres_ifs_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz',\n",
    "    case_id_list=au_case_ids)\n",
    "\n",
    "# subset europe\n",
    "eu_fourv2_severe_plot_csi = results_utils.subset_results_to_xarray(results_df=fourv2_ar_results, \n",
    "    forecast_source=fourv2_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz',\n",
    "    case_id_list=eu_case_ids)\n",
    "eu_gc_severe_plot_csi = results_utils.subset_results_to_xarray(results_df=gc_ar_results, \n",
    "    forecast_source=gc_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz',\n",
    "    case_id_list=eu_case_ids)\n",
    "eu_pangu_severe_plot_csi  = results_utils.subset_results_to_xarray(results_df=pang_ar_results, \n",
    "    forecast_source=pangu_gfs_cira_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz',\n",
    "    case_id_list=eu_case_ids)\n",
    "eu_hres_severe_plot_csi = results_utils.subset_results_to_xarray(results_df=hres_ar_results, \n",
    "    forecast_source=hres_ifs_settings['forecast_source'], \n",
    "    target_source='ERA5', metric='CriticalSuccessIndex', init_time='zeroz',\n",
    "    case_id_list=eu_case_ids)\n",
    "\n",
    "\n",
    "# make a global settings so we can compare\n",
    "fourv2_global_settings = fourv2_gfs_cira_settings | fourv2_style | global_group_style\n",
    "pangu_global_settings = pangu_gfs_cira_settings | pangu_style | global_group_style\n",
    "gc_global_settings = gc_gfs_cira_settings | gc_style | global_group_style\n",
    "hres_global_settings = hres_ifs_settings | hres_style | global_group_style "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d4febc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the graphics objects\n",
    "hres_graphics = pd.read_pickle(basepath + 'saved_data/hres_ar_graphics.pkl')\n",
    "pangu_graphics = pd.read_pickle(basepath + 'saved_data/pang_ar_graphics.pkl')\n",
    "fourv2_graphics = pd.read_pickle(basepath + 'saved_data/fourv2_ar_graphics.pkl')\n",
    "gc_graphics = pd.read_pickle(basepath + 'saved_data/gc_ar_graphics.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba2a214",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_error_array_for_heatmap(results_array, hres_results, forecast_sources, \n",
    "    target_source, metric_strs, init_time, lead_time_days, higher_is_better_list):\n",
    "    \"\"\"\n",
    "    This function takes in an array of results and parameters to say which results to grab and returns \n",
    "    error arrays and relative arrays for global, north america, and europe.\n",
    "    \"\"\"\n",
    "    # now make the array for the scorecard\n",
    "    global_rel_error = {}\n",
    "    global_error = {}\n",
    "\n",
    "    na_rel_error = {}\n",
    "    na_error = {}\n",
    "\n",
    "    au_rel_error = {}\n",
    "    au_error = {}\n",
    "\n",
    "    eu_rel_error = {}\n",
    "    eu_error = {}\n",
    "\n",
    "\n",
    "    for i, metric in enumerate(metric_strs):\n",
    "        # initialize the arrays\n",
    "        global_rel_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "        global_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "\n",
    "        na_rel_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "        na_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "\n",
    "        au_rel_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "        au_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "\n",
    "        eu_rel_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "        eu_error[metric] = np.zeros((len(results_array), len(lead_time_days)))\n",
    "\n",
    "        higher_is_better = higher_is_better_list[i]\n",
    "\n",
    "        for j, results_df in enumerate(results_array):\n",
    "            my_mean, my_relative_error = results_utils.compute_relative_error(results_df, \n",
    "                forecast_source=forecast_sources[j], \n",
    "                comparison_results_df=hres_results, \n",
    "                comparison_forecast_source=hres_settings['forecast_source'], \n",
    "                target_source=target_source, \n",
    "                metric=metric, init_time=init_time, lead_time_days=lead_time_days, \n",
    "                higher_is_better=higher_is_better)\n",
    "            global_error[metric][j, :] = my_mean\n",
    "            global_rel_error[metric][j, :] = my_relative_error\n",
    "\n",
    "            na_mean, na_relative_error = results_utils.compute_relative_error(results_df,\n",
    "                forecast_source=forecast_sources[j], \n",
    "                comparison_results_df=hres_results, \n",
    "                comparison_forecast_source=hres_settings['forecast_source'], \n",
    "                target_source=target_source, \n",
    "                metric=metric, init_time=init_time, lead_time_days=lead_time_days, \n",
    "                case_ids=na_case_ids, \n",
    "                higher_is_better=higher_is_better)\n",
    "            na_error[metric][j, :] = na_mean\n",
    "            na_rel_error[metric][j, :] = na_relative_error\n",
    "\n",
    "            au_mean, au_relative_error = results_utils.compute_relative_error(results_df,\n",
    "                forecast_source=forecast_sources[j], \n",
    "                comparison_results_df=hres_results, \n",
    "                comparison_forecast_source=hres_settings['forecast_source'], \n",
    "                target_source=target_source, \n",
    "                metric=metric, init_time=init_time, lead_time_days=lead_time_days, \n",
    "                case_ids=au_case_ids, \n",
    "                higher_is_better=higher_is_better)\n",
    "            au_error[metric][j, :] = au_mean\n",
    "            au_rel_error[metric][j, :] = au_relative_error\n",
    "\n",
    "            eu_mean, eu_relative_error = results_utils.compute_relative_error(results_df,\n",
    "                forecast_source=forecast_sources[j], \n",
    "                comparison_results_df=hres_results, \n",
    "                comparison_forecast_source=hres_settings['forecast_source'], \n",
    "                target_source=target_source, \n",
    "                metric=metric, init_time=init_time, lead_time_days=lead_time_days, \n",
    "                case_ids=eu_case_ids, \n",
    "                higher_is_better=higher_is_better)\n",
    "            eu_error[metric][j, :] = eu_mean    \n",
    "            eu_rel_error[metric][j, :] = eu_relative_error\n",
    "\n",
    "    return global_error, global_rel_error, na_error, na_rel_error, au_error, au_rel_error, eu_error, eu_rel_error\n",
    "\n",
    "# setup for the scorecard\n",
    "# Grab means for each metric for each model\n",
    "ar_metric_str = ['CriticalSuccessIndex', 'spatial_displacement']\n",
    "ar_display_str = ['Critical Success Index', 'Spatial Displacement']\n",
    "ar_metric_higher_is_better = [True, False]\n",
    "\n",
    "lead_time_days = [1, 3, 5, 7, 10]\n",
    "\n",
    "ar_results_array = [hres_ar_results, gc_ar_results, \n",
    "    pang_ar_results, fourv2_ar_results]\n",
    "forecast_source = [hres_ifs_settings['forecast_source'], \n",
    "    gc_gfs_cira_settings['forecast_source'], \n",
    "    pangu_gfs_cira_settings['forecast_source'],\n",
    "    fourv2_gfs_cira_settings['forecast_source']]\n",
    "\n",
    "(global_ar_error, global_rel_ar_error, na_ar_error, na_rel_ar_error, \n",
    "    au_ar_error, au_rel_ar_error, eu_ar_error, eu_rel_ar_error) = \\\n",
    "    get_error_array_for_heatmap(ar_results_array, hres_ar_results, \n",
    "    forecast_source, 'ERA5', ar_metric_str, 'zeroz', lead_time_days, ar_metric_higher_is_better )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f2227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_ivt_and_maks(graphics_obect, lead_time_hours):\n",
    "    # select the right lead time\n",
    "    lead_time_td = pd.Timedelta(hours=lead_time_hours)\n",
    "    ivt = graphics_obect.integrated_vapor_transport.sel(lead_time=lead_time_td, method=\"nearest\")\n",
    "    ar_mask = graphics_obect.atmospheric_river_mask.sel(lead_time=lead_time_td, method=\"nearest\")\n",
    "\n",
    "    # select the right valid time (hack for now to always select the first valid time)\n",
    "    valid_time = graphics_obect.integrated_vapor_transport.valid_time[0]\n",
    "    ivt2 = ivt.sel(valid_time=valid_time, method=\"nearest\")\n",
    "    ar_mask2 = ar_mask.sel(valid_time=valid_time, method=\"nearest\")\n",
    "    return ivt2, ar_mask2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00caedbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.gridspec import GridSpec, GridSpecFromSubplotSpec\n",
    "\n",
    "n_rows_top = 4\n",
    "n_rows_bottom = 2\n",
    "n_rows = n_rows_top + n_rows_bottom\n",
    "n_cols_top = 2  # Columns for top 3 rows\n",
    "n_cols_bottom = 4  # Columns for bottom 2 rows (more Cartopy plots)\n",
    "figsize = (8 * max(n_cols_top, n_cols_bottom), 6.5 * n_rows)\n",
    "print(figsize)\n",
    "\n",
    "# Create figure first\n",
    "fig = plt.figure(figsize=figsize)\n",
    "\n",
    "# Main GridSpec: 6 rows, use max columns for layout\n",
    "# Top 4 rows will use 2 columns, bottom 2 rows will use 4 columns\n",
    "gs_main = GridSpec(n_rows, 1, figure=fig, left=0.05, right=0.95, top=0.98, bottom=0.02,\n",
    "    wspace=.1, hspace=1)\n",
    "\n",
    "# Create subplots for top 4 rows (2 columns each)\n",
    "gs_top = GridSpecFromSubplotSpec(n_rows_top, n_cols_top, subplot_spec=gs_main[0:n_rows_top, 0],\n",
    "                                  wspace=0.02, hspace=0.3,\n",
    "                                  width_ratios=[1, 1])\n",
    "\n",
    "# Create subplots for bottom 2 rows (4 columns each - all Cartopy)\n",
    "gs_bottom = GridSpecFromSubplotSpec(n_rows_bottom, n_cols_bottom, subplot_spec=gs_main[n_rows_top:n_rows, 0],\n",
    "                                     wspace=0.15, hspace=0.05)\n",
    "\n",
    "# Create all subplots - initialize as array with shape (n_rows, max_cols)\n",
    "max_cols = max(n_cols_top, n_cols_bottom)\n",
    "axs = np.empty((n_rows, max_cols), dtype=object)\n",
    "\n",
    "# Top n_rows_top rows: 2 columns (Cartopy on left, regular on right)\n",
    "for i in range(n_rows_top):\n",
    "    # Left column: Cartopy\n",
    "    ax_cartopy = fig.add_subplot(gs_top[i, 0], projection=ccrs.PlateCarree())\n",
    "    axs[i,0] = ax_cartopy\n",
    "\n",
    "    # Right column: Regular matplotlib\n",
    "    ax_regular = fig.add_subplot(gs_top[i, 1])\n",
    "    axs[i,1] = ax_regular\n",
    "\n",
    "# Bottom n_rows_bottom rows: 4 columns (all Cartopy)\n",
    "for i in range(n_rows_bottom):\n",
    "    for j in range(n_cols_bottom):\n",
    "        ax_cartopy = fig.add_subplot(gs_bottom[i, j], projection=ccrs.PlateCarree())\n",
    "        axs[i+n_rows_top,j] = ax_cartopy\n",
    "\n",
    "\n",
    "# the left hand column of figure one shows all of the cases for each event type\n",
    "# plot the cases for each event type\n",
    "print(\"plotting the cases for each event type\")\n",
    "plot_utils.plot_all_cases(\n",
    "    ewb_cases,\n",
    "    event_type=\"atmospheric_river\",\n",
    "    fill_boxes=True,\n",
    "    ax=axs[0, 0],\n",
    ")\n",
    "# plot the cases for north america\n",
    "plot_utils.plot_all_cases(\n",
    "    ewb_cases,\n",
    "    event_type=\"atmospheric_river\",\n",
    "    bounding_box=na_bounding_box,\n",
    "    fill_boxes=True,\n",
    "    ax=axs[1, 0],\n",
    ")\n",
    "\n",
    "# plot the cases for europe\n",
    "plot_utils.plot_all_cases(\n",
    "    ewb_cases,\n",
    "    event_type=\"atmospheric_river\",\n",
    "    bounding_box=eu_bounding_box,\n",
    "    fill_boxes=True,\n",
    "    ax=axs[2, 0],\n",
    ")\n",
    "# plot the cases for australia\n",
    "plot_utils.plot_all_cases(\n",
    "    ewb_cases,\n",
    "    event_type=\"atmospheric_river\",\n",
    "    bounding_box=au_bounding_box,\n",
    "    fill_boxes=True,\n",
    "    ax=axs[3, 0],\n",
    ")\n",
    "\n",
    "# plot the heatmaps for each of the subareas\n",
    "ar_settings = {}\n",
    "ar_settings[\"subplot_titles\"] = ar_display_str\n",
    "ar_settings[\"metric_str\"] = ar_metric_str\n",
    "ar_settings[\"lead_time_days\"] = lead_time_days\n",
    "ar_settings[\"model_order\"] = [\"HRES IFS\", \"FourCastNet v2\", \"GraphCast\", \"Pangu\"]\n",
    "\n",
    "# second column of figure 2 shows the scorecard\n",
    "plot_utils.plot_heatmap(\n",
    "    global_rel_ar_error,\n",
    "    global_ar_error,\n",
    "    ar_settings,\n",
    "    ax=axs[0, 1],\n",
    ")\n",
    "\n",
    "plot_utils.plot_heatmap(\n",
    "    na_rel_ar_error,\n",
    "    na_ar_error,\n",
    "    ar_settings,\n",
    "    ax=axs[1, 1],\n",
    ")\n",
    "\n",
    "plot_utils.plot_heatmap(\n",
    "    eu_rel_ar_error,\n",
    "    eu_ar_error,\n",
    "    ar_settings,\n",
    "    ax=axs[2, 1],\n",
    ")\n",
    "\n",
    "plot_utils.plot_heatmap(\n",
    "    au_rel_ar_error,\n",
    "    au_ar_error,\n",
    "    ar_settings,\n",
    "    ax=axs[3, 1],\n",
    "    show_colorbar=True,\n",
    ")\n",
    "\n",
    "# now plot the ar case studies\n",
    "my_id = 113\n",
    "lead_time_hours = 72\n",
    "hres_ivt, hres_ar_mask = select_ivt_and_maks(hres_graphics[my_id], lead_time_hours)\n",
    "gc_ivt, gc_ar_mask = select_ivt_and_maks(gc_graphics[my_id], lead_time_hours)\n",
    "pangu_ivt, pangu_ar_mask = select_ivt_and_maks(pangu_graphics[my_id], lead_time_hours)\n",
    "fourv2_ivt, fourv2_ar_mask = select_ivt_and_maks(fourv2_graphics[my_id], lead_time_hours)\n",
    "\n",
    "# setup a four panel subplot with cartopy subfigures using GridSpec\n",
    "ar_plot_utils.plot_ar_mask_single_timestep(ivt_data=hres_ivt, ar_mask=hres_ar_mask, \n",
    "    title=\"HRES\", ax=axs[4,0], colorbar=False)\n",
    "\n",
    "ar_plot_utils.plot_ar_mask_single_timestep(ivt_data=gc_ivt, ar_mask=gc_ar_mask, \n",
    "    title=\"GraphCast\", ax=axs[4,1], colorbar=False)\n",
    "\n",
    "ar_plot_utils.plot_ar_mask_single_timestep(ivt_data=pangu_ivt, ar_mask=pangu_ar_mask, \n",
    "    title=\"Pangu\", ax=axs[4,2], colorbar=False)\n",
    "\n",
    "ar_plot_utils.plot_ar_mask_single_timestep(ivt_data=fourv2_ivt, ar_mask=fourv2_ar_mask, \n",
    "    title=\"ForeCastNet V2\", ax=axs[4,3], colorbar=False)\n",
    "\n",
    "# put a title on the 5th row\n",
    "# Get the position from row 5 axes to position title above it\n",
    "# Use the first axes in row 5 to get position (now that it's been plotted)\n",
    "ax_row5 = axs[4, 0]\n",
    "pos_row5 = ax_row5.get_position()\n",
    "# Position title above row 5, centered\n",
    "# get_position returns a Bbox in figure coordinates (0-1)\n",
    "title_y_fig = pos_row5.y1 + 0.015  # Position slightly above row 5 top edge\n",
    "valid_time = hres_graphics[my_id].integrated_vapor_transport.valid_time[0].values\n",
    "# convert the valid time to a datetime object\n",
    "valid_time_dt = pd.to_datetime(valid_time)\n",
    "# Use strftime() to format the string\n",
    "valid_time_str = valid_time_dt.strftime('%m/%d/%Y, %H:%M')\n",
    "fig.text(0.5, title_y_fig, f\"Case id {my_id}, Valid Time: {valid_time_str}, Lead Time: {lead_time_hours} hours\", \n",
    "         size=32, ha='center', va='bottom', transform=fig.transFigure)\n",
    "\n",
    "\n",
    "# now plot the ar case studies\n",
    "my_id = 116\n",
    "lead_time_hours = 72\n",
    "hres_ivt, hres_ar_mask = select_ivt_and_maks(hres_graphics[my_id], lead_time_hours)\n",
    "gc_ivt, gc_ar_mask = select_ivt_and_maks(gc_graphics[my_id], lead_time_hours)\n",
    "pangu_ivt, pangu_ar_mask = select_ivt_and_maks(pangu_graphics[my_id], lead_time_hours)\n",
    "fourv2_ivt, fourv2_ar_mask = select_ivt_and_maks(fourv2_graphics[my_id], lead_time_hours)\n",
    "\n",
    "# setup a four panel subplot with cartopy subfigures using GridSpec\n",
    "ar_plot_utils.plot_ar_mask_single_timestep(ivt_data=hres_ivt, ar_mask=hres_ar_mask, \n",
    "    title=\"HRES\", ax=axs[5,0], colorbar=False)\n",
    "\n",
    "ar_plot_utils.plot_ar_mask_single_timestep(ivt_data=gc_ivt, ar_mask=gc_ar_mask, \n",
    "    title=\"GraphCast\", ax=axs[5,1], colorbar=False)\n",
    "\n",
    "ar_plot_utils.plot_ar_mask_single_timestep(ivt_data=pangu_ivt, ar_mask=pangu_ar_mask, \n",
    "    title=\"Pangu\", ax=axs[5,2], colorbar=False)\n",
    "\n",
    "ar_plot_utils.plot_ar_mask_single_timestep(ivt_data=fourv2_ivt, ar_mask=fourv2_ar_mask, \n",
    "    title=\"ForeCastNet V2\", ax=axs[5,3], colorbar=False)\n",
    "\n",
    "# put a title on the 5th row\n",
    "# Get the position from row 5 axes to position title above it\n",
    "# Use the first axes in row 5 to get position (now that it's been plotted)\n",
    "ax_row5 = axs[5, 0]\n",
    "pos_row5 = ax_row5.get_position()\n",
    "# Position title above row 5, centered\n",
    "# get_position returns a Bbox in figure coordinates (0-1)\n",
    "title_y_fig = pos_row5.y1 + 0.015  # Position slightly above row 5 top edge\n",
    "valid_time = hres_graphics[my_id].integrated_vapor_transport.valid_time[0].values\n",
    "# convert the valid time to a datetime object\n",
    "valid_time_dt = pd.to_datetime(valid_time)\n",
    "# Use strftime() to format the string\n",
    "valid_time_str = valid_time_dt.strftime('%m/%d/%Y, %H:%M')\n",
    "fig.text(0.5, title_y_fig, f\"Case id {my_id}, Valid Time: {valid_time_str}, Lead Time: {lead_time_hours} hours\", \n",
    "         size=32, ha='center', va='bottom', transform=fig.transFigure)\n",
    "\n",
    "# show the colorbar below the bottom row (row 5)\n",
    "# Create a ScalarMappable for the colorbar\n",
    "from matplotlib.cm import ScalarMappable\n",
    "cmap, norm = ar_plot_utils.setup_atmospheric_river_colormap_and_levels()\n",
    "sm = ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])  # Empty array, we just need the colormap/norm\n",
    "\n",
    "# Get the position from row 5 (bottom row) subplots to position colorbar below them\n",
    "pos0 = gs_bottom[1, 0].get_position(fig)\n",
    "pos3 = gs_bottom[1, 3].get_position(fig)\n",
    "# Create axes below row 5 that spans all 4 columns\n",
    "# Position it just below row 5, using a small height\n",
    "cbar_y = pos0.y0 - pos0.height * 0.2  # Position below row 5\n",
    "cbar_height = pos0.height * 0.15  # Height for colorbar\n",
    "cbar_ax = fig.add_axes([pos0.x0, cbar_y, pos3.x1 - pos0.x0, cbar_height])\n",
    "\n",
    "# Add horizontal colorbar below bottom row\n",
    "cbar = fig.colorbar(sm, cax=cbar_ax, orientation='horizontal')\n",
    "cbar.set_label(\"Integrated Vapor Transport (kgm^-1s^-1)\", size=32)\n",
    "cbar.ax.tick_params(labelsize=24)\n",
    "\n",
    "fig.savefig(basepath + \"saved_data/figure4.png\", dpi=600, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
